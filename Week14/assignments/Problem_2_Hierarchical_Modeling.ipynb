{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8044c42e2e9b1c1b446c2837ebb2975c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week11` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a8cdb33ab51cf69d2ca0054a228894aa",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 2. Hierarchical Modeling.\n",
    "\n",
    "In this problem, we will implement a hierarchical model to estimate the distribution of departure delays in December of 2001 ([airline on-time performance data](http://stat-computing.org/dataexpo/2009/the-data.html).)\n",
    "\n",
    "![](https://github.com/UI-DataScience/accy570-fa16/raw/master/Week14/images/hierarchical.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9d143b638f553383490e9cc667a85ea",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "\n",
    "from nose.tools import assert_equal, assert_true, assert_is_instance\n",
    "from numpy.testing import assert_array_almost_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b83a8583c7f2eec5c3a905b2b536c21b",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use the [airline on-time performance data](http://stat-computing.org/dataexpo/2009/). For simplicity, we limit our analysis to flights that departed from [CMI](https://en.wikipedia.org/wiki/University_of_Illinois_Willard_Airport) in December."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1daedc46e37ea922c89ee065106c6c1d",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "filename = '/home/data_scientist/data/2001.csv'\n",
    "\n",
    "usecols = (1, 2, 15, 16)\n",
    "columns = ['Month', 'DayofMonth', 'DepDelay', 'Origin']\n",
    "\n",
    "all_data = pd.read_csv(filename, header=0, na_values=['NA'], usecols=usecols, names=columns)\n",
    "\n",
    "local = all_data[\n",
    "    (all_data['Origin'] == 'CMI') & # use only flights departed from Chicago\n",
    "    (all_data['Month'] == 12) # consider only December\n",
    "    ]\n",
    "local = local.drop(['Month', 'Origin'], axis=1) # we don't need Month and Origin columns\n",
    "local = local.dropna() # drop missing values\n",
    "\n",
    "print(local.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97cff027e892bbf21dec3e991234a500",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will use a [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) (see the next section) but the Poisson distribution does not allow negative means. That is, $\\mu > 0$ in\n",
    "\n",
    "$$ Poisson(\\mu) = P(x\\mid\\mu) = \\frac{e^{-\\mu}\\mu^{x}}{x!}\\quad\\textrm{for}\\, x=0,1,2,\\cdots $$\n",
    "\n",
    "However, there exist some negative values in `DepDelay`, as shown in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ad5333db87d1394a4cdea34093ed36f2",
     "grade": false,
     "grade_id": "print_min",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.DepDelay.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5271fe2023aad6a2ed5c5f41c9adabff",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This condition can be avoided by a simple shift in the domain, so let's add 15 minutes to all departure delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b48de1972ec1e79ab0db5dea6cc9378a",
     "grade": false,
     "grade_id": "shift_column",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def shift_column(df, field, shift):\n",
    "    return pd.concat([df.drop(field, axis=1), df[field].apply(lambda x: x + shift)], axis=1) \n",
    "\n",
    "local_shifted = shift_column(local, 'DepDelay', 15)\n",
    "\n",
    "print(local_shifted.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bd4acdfb57c6c72b5901da4213182c64",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The following code cell asserts that all values in `DepDelay` are non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7bb5264a5ec8aa4146a469afb36c90df",
     "grade": false,
     "grade_id": "assert_non_negative",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal((local_shifted.DepDelay.values < 0).sum(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f6818909c4be012319f5ca6027f7a92",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For simplicity, let's remove some outliers and only consider departure delays less than 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1fb6230ff9452a6cd6258eee1fc8e068",
     "grade": false,
     "grade_id": "assert_less_than_60",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local_shifted = local_shifted[local_shifted['DepDelay'] < 60]\n",
    "# check if there are any values greater than 60\n",
    "assert_equal((local_shifted.DepDelay.values > 60).sum(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "65cf61d9b0b0ac037bd9529ad102b450",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In the following section, we model each day independently, modeling paramters $\\mu_i$ of the Poisson distribution for each day of December, $i=1, 2, \\cdots, 31$. The reasoning behind this is that the departure delays will depend on different conditions of each day, e.g. the weather, whether it's a weekend or a weekday, whehter it's a holiday, etc.\n",
    "\n",
    "Simiarly to the use of `county_idx` in one of the [required readings](https://github.com/UI-DataScience/accy570-fa16/blob/master/Week14/lesson2.md), we need a way to map `mu` (an array of length 31) to an array that has the length as `local_shifted`. Read [GLM: Hierarchical Linear Regression](https://pymc-devs.github.io/pymc3/notebooks/GLM-hierarchical.html) to see how `county_idx` is used [here](https://pymc-devs.github.io/pymc3/notebooks/GLM-hierarchical.html#Hierarchical-Model) and how `participants_idx` is used [here](http://nbviewer.jupyter.org/github/markdregan/Bayesian-Modelling-in-Python/blob/master/Section%203.%20Hierarchical%20modelling.ipynb). \n",
    "\n",
    "We can use the `DayofMonth` column to create `date_idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f198828dc8d7f74793ec72e618d7129f",
     "grade": false,
     "grade_id": "date_idx",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "date_idx = local_shifted['DayofMonth'].values - 1\n",
    "print(date_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b4efa4f545731fe311816f63e73f907",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "And we can use `date_idx` as follows:\n",
    "\n",
    "```python\n",
    ">>> mu = np.arange(31)\n",
    ">>> print(mu)\n",
    "```\n",
    "```\n",
    "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
    " 25 26 27 28 29 30]\n",
    "```\n",
    "```python\n",
    ">>> print(mu[date_idx])\n",
    "```\n",
    "```\n",
    "[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 17 18 19 21 22 23 24 25 26 27\n",
    " 28 29 30  0  1  2  3  4  5  6  7  8 10 12 14 16 17 18 20 25 26 28 29 30  0\n",
    "  1  3  4  5  6  7  8  9 10 12 14 15 16 18 20 21 22 24 26 27 28 29 30  2  3\n",
    "  4  5  6  8  9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 27 28 29 30  0\n",
    "  2  3  4  8  9 10 11 13 15 17 18 19 20 21 22 23 24 25 26 27 29]\n",
    "```\n",
    "```python\n",
    ">>> len(mu[date_idx]) == len(local_shifted)\n",
    "```\n",
    "```\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6606f7b24a227f4f6fac181997492ba9",
     "grade": false,
     "grade_id": "markdown_8",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Use PyMC3 to implement a hierarchical model\n",
    "\n",
    "- Implement the following hierarchical model using `pymc3`:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{ji} &\\sim Poisson(\\mu_{i}) \\\\\n",
    "\\mu_i &= Gamma(\\alpha=\\alpha_\\mu, \\beta=\\beta_\\mu) \\\\\n",
    "\\alpha_\\mu &= Gamma(\\alpha=1, \\beta=1) \\\\\n",
    "\\beta_\\mu &= Gamma(\\alpha=1, \\beta=1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "for each flight $j$ and each day $i$. Here, $Gamma(\\alpha, \\beta)$ is the [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution).\n",
    "\n",
    "- Use the names `mu`, `hyper_alpha_mu`, and `hyper_beta_mu` for $\\mu_i$, $\\alpha_\\mu$, and $\\beta_\\mu$, respectively.\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The bulk of the code is provided. Fill in the spaces between\n",
    "```python\n",
    "with pm.Model() as model:\n",
    "```\n",
    "and\n",
    "```python\n",
    "    y_est = pm.Poisson('y_est', mu=mu[idx], observed=X)\n",
    "```\n",
    "\n",
    "- You basically need to write only 3 lines:\n",
    "  1. Define `hyper_alpha_mu`,\n",
    "  2. Define `hyper_beta_mu`, and\n",
    "  3. Define `mu`.\n",
    "  \n",
    "- Specify the `shape` paramter in `mu`. The shape of `mu` should be equal to `n_days` because we have 31 days and we sample the distribution for each day. For example, your definition of `mu` should look something like\n",
    "  ```python\n",
    "  mu = pm.Gamma(..., shape=n_days)\n",
    "  ```\n",
    "  (The `...` symbol in the above example is not code. You have fill this part in.)\n",
    "\n",
    "- Note there are two ways to specify a [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution): either in terms of alpha and beta or mean and standard deviation. In this problem, we parametrize it in terms of alpha (the shape parameter) and beta (the rate parameter). Thus, you should use the optional paramters, `alpha` and `beta`, in [pymc3.Gamma()](https://pymc-devs.github.io/pymc3/api.html#pymc3.distributions.continuous.Gamma).\n",
    "\n",
    "- `pymc3.find_MAP()` estimates the model paramters with the [maximum a posteriori (MAP) method](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation).\n",
    "\n",
    "- `pymc3.Metropolis()` uses the [Metropolis-Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) to generate posterior samples.\n",
    "\n",
    "- Note that for reproducibility we use the `random_seed` parameter in `pymc3.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d6c779c6097e1254d354fb5a36216f69",
     "grade": false,
     "grade_id": "sample_posterior_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_posterior(X, idx, n_samples=2000, random_seed=0):\n",
    "    \"\"\"\n",
    "    A hierarchical Poisson model.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    X: A numpy array\n",
    "    y: A numpy array\n",
    "    n_samples: The number of samples to draw in pymc3.sample().\n",
    "               Defaults to 2000.\n",
    "    random_seed: An int. Used in pymc3.sample().\n",
    "                 Defaults to 0.\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    A pymc3.MultiTrace object with access to sampling values.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_days = 31\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        y_est = pm.Poisson('y_est', mu=mu[idx], observed=X)\n",
    "        \n",
    "        y_pred = pm.Poisson('y_pred', mu=mu[idx], shape=len(X))\n",
    "    \n",
    "        start = pm.find_MAP()\n",
    "        step = pm.Metropolis(start=start)\n",
    "        trace = pm.sample(n_samples, step=step, start=start, random_seed=random_seed)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a491764db07b8c5490bb04a40dde190d",
     "grade": false,
     "grade_id": "sample_posterior_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "hierarchical_trace = sample_posterior(X=local_shifted['DepDelay'].values, idx=date_idx, n_samples=80000, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "aeddb35936ce5bd301b0be4b65f9e940",
     "grade": true,
     "grade_id": "test_1",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(hierarchical_trace, pm.backends.base.MultiTrace)\n",
    "\n",
    "assert_true('mu' in hierarchical_trace.varnames)\n",
    "assert_true('hyper_alpha_mu' in hierarchical_trace.varnames)\n",
    "assert_true('hyper_beta_mu' in hierarchical_trace.varnames)\n",
    "\n",
    "for v in hierarchical_trace.varnames:\n",
    "    assert_equal(len(hierarchical_trace[v]), 80000)\n",
    "    \n",
    "assert_equal(hierarchical_trace['mu'].shape[1], 31)\n",
    "\n",
    "# note the length of array is 31 for 31 days in the month\n",
    "assert_array_almost_equal(\n",
    "    hierarchical_trace['mu'][0],\n",
    "    [ 5.15005593,  16.62475093,   5.03444126,   5.40358022,\n",
    "      8.40843764,   5.61251444,   9.65902678,   8.29027819,\n",
    "      5.77918745,   7.8091926 ,   6.7182054 ,  11.21074812,\n",
    "     11.27763162,   7.45102393,  13.82115361,  12.86502678,\n",
    "      9.40608048,   7.23111944,  12.63401805,  13.31619368,\n",
    "     13.35869547,   6.9998901 ,   5.72812911,   5.64635637,\n",
    "      4.68759738,   8.8497243 ,  10.81517309,   7.23111939,\n",
    "      4.57198275,   9.06575018,   4.57198268]\n",
    "   )\n",
    "assert_almost_equal(hierarchical_trace['hyper_alpha_mu'][0], 5.5450171527810559)\n",
    "assert_almost_equal(hierarchical_trace['hyper_beta_mu'][0], 0.64942393608716098)\n",
    "\n",
    "assert_array_almost_equal(\n",
    "    hierarchical_trace['mu'][-1],\n",
    "    [ 8.08654951,  34.0837555 ,   7.57008046,  10.5119628 ,\n",
    "     18.50107315,  11.78745223,  18.09940974,  16.12241455,\n",
    "     12.13169849,  12.99963025,  13.07349382,  21.31053708,\n",
    "     27.47656623,  11.39435595,  28.41184314,  22.42567766,\n",
    "     16.35230353,  12.67814566,  26.50712576,  24.24614846,\n",
    "     21.82844008,  15.66077269,   7.92093998,  10.11164246,\n",
    "      8.82131075,  19.24463488,  23.58609882,  13.27383155,\n",
    "      8.12750503,  16.63355873,   7.75384526]\n",
    "     )\n",
    "assert_array_almost_equal(\n",
    "    hierarchical_trace['hyper_alpha_mu'][-5:],\n",
    "    [ 4.80090357,  4.9096912 ,  4.92489959,  4.63708045,  4.63708045]\n",
    ")\n",
    "assert_array_almost_equal(\n",
    "    hierarchical_trace['hyper_beta_mu'][-5:],\n",
    "    [ 0.29688427,  0.29688427,  0.29688427,  0.29688427,  0.29688427]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26a8dbc2641ae4c0e8699650ccc78eae",
     "grade": false,
     "grade_id": "markdown_10",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's check our model by inspecting the sampling output. A simple posterior plot can be created using `traceplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7127d602868dc0d10dd805e1d0ef8a38",
     "grade": false,
     "grade_id": "traceplot",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pm.traceplot(hierarchical_trace[40000:], varnames=['mu', 'hyper_alpha_mu', 'hyper_beta_mu']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visually inspect the fit of our model by comparing the posterior predictive distribution and the distribution of the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "037962740775f907499596d8fc69c9a2",
     "grade": false,
     "grade_id": "plot",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x_lim = 60\n",
    "n_burn = 40000\n",
    "\n",
    "# we discard burn-in and use every 1000th trace\n",
    "y_pred = hierarchical_trace.get_values('y_pred')[n_burn::1000].ravel()\n",
    "\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(2, sharex=True, figsize=(12,6))\n",
    "\n",
    "ax[0].hist(y_pred, range=[0, x_lim], bins=x_lim, histtype='stepfilled')   \n",
    "ax[0].set_xlim(1, x_lim)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_title('Posterior predictive distribution')\n",
    "\n",
    "ax[1].hist(local_shifted.DepDelay.values, range=[0, x_lim], bins=x_lim, histtype='stepfilled')\n",
    "ax[1].set_xlabel('Departure Delay + 15 minutes')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_title('Distribution of observed data')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
