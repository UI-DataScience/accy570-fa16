{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a98c739c45025e75b7a8a39168517825",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "91b4d14ad0ac88372ab410a573896949",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 1. Bayesian Linear Regression.\n",
    "\n",
    "In this problem, we will use `pymc3` to estimate the model parameters of a linear regression model that predicts `AirTime` from `Distance`.\n",
    "\n",
    "![](https://github.com/UI-DataScience/accy570-fa16/raw/master/Week14/images/bayesian_linear_regression.png)\n",
    "\n",
    "(Compare this plot with the plots in [ACCY571 Week 5 Problem 1](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week5/assignments/Problem_1_Seaborn_Linear_Regression.ipynb) and [Problem 2](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week5/assignments/Problem_2_Statsmodels_Linear_Regression.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9d143b638f553383490e9cc667a85ea",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "\n",
    "from nose.tools import assert_equal, assert_true, assert_is_instance\n",
    "from numpy.testing import assert_array_almost_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bc017c4181e7234e9d7124eda43a5deb",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Suppose we are given the air times (in minutes) and distances traveled (in miles) of 20 different flights, and we want to find the relationship between the air time and distance by fitting a linear regression model using Bayesian methods. In the following code cell, `data` is given as a Pandas DataFrame.\n",
    "\n",
    "```python\n",
    ">>> print(data)\n",
    "```\n",
    "```\n",
    "    AirTime  Distance\n",
    "0        60       361\n",
    "1        84       569\n",
    "2        95       588\n",
    "3       182      1172\n",
    "4       337      2565\n",
    "5       119       861\n",
    "6        87       665\n",
    "7       103       787\n",
    "8        55       228\n",
    "9        47       197\n",
    "10      127       978\n",
    "11      215      1745\n",
    "12      213      1605\n",
    "13       59       373\n",
    "14       31       156\n",
    "15       57       209\n",
    "16       88       505\n",
    "17       42       224\n",
    "18       45       282\n",
    "19      102       862\n",
    "```\n",
    "\n",
    "(Note: This is the same data we use in [ACCY 571 Week 5](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week5/assignments/Problem_1_Seaborn_Linear_Regression.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\"AirTime\": [60, 84, 95, 182, 337, 119, 87, 103, 55, 47,\n",
    "        127, 215, 213, 59, 31, 57, 88, 42, 45, 102],\n",
    "     \"Distance\": [361, 569, 588, 1172, 2565, 861, 665, 787, 228, 197,\n",
    "        978, 1745, 1605, 373, 156, 209, 505, 224, 282, 862]}\n",
    ")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bbc638843688d29e4bf675c9b2f9577b",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Use PyMC3 to fit a linear regression model\n",
    "\n",
    "- Complete the `get_trace()` function which implements the following model using `pymc3`:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y  &\\sim \\mathcal{N}(\\mu, \\sigma^2) \\\\\n",
    "\\mu &= \\alpha + \\beta X \\\\\n",
    "\\alpha &\\sim \\mathcal{N}(\\mu=0, \\sigma^2=1) \\\\\n",
    "\\beta &\\sim \\mathcal{N}(\\mu=10, \\sigma^2=1) \\\\\n",
    "\\sigma &\\sim \\mathcal{U}(0, 100)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\mathcal{N}(\\mu, \\sigma^2)$ denotes the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) and $\\mathcal{U}$ is the <a href=\"https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)\">uniform distribution</a>.\n",
    "\n",
    "- Use the `pymc3` variable names `alpha`, `beta`, and `sigma` for $\\alpha$, $\\beta$, and $\\sigma$, respectively. (The [Bayesian Modeling notebook](https://github.com/UI-DataScience/accy570-fa16/blob/master/Week14/notebooks/intro2pp-bm.ipynb) uses the names `Intercept`, `Slope`, and `sigma`. Do not use `Intercept` and `Slope`. Be sure to change variable names.)\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The bulk of the code is provided. Fill in the spaces between\n",
    "```python\n",
    "with pm.Model() as model:\n",
    "```\n",
    "and\n",
    "```python\n",
    "    y = pm.Normal('y', mu=y_exp, sd=sigma, observed=y)\n",
    "```\n",
    "\n",
    "- You basically need to write only 4 lines:\n",
    "  1. Define `alpha` (the intercept),\n",
    "  2. Define `beta` (the slope),\n",
    "  3. Define `sigma` (the standard deviaiton of the posterior distibution $Y$), and\n",
    "  4. Define `y_exp` (the mean of the posterior distribution).\n",
    "  \n",
    "- Refer to the [Bayesian Modeling notebook](https://github.com/UI-DataScience/accy570-fa16/blob/master/Week14/notebooks/intro2pp-bm.ipynb) and [Getting Started with PyMC3](https://pymc-devs.github.io/pymc3/notebooks/getting_started.html).\n",
    "- `pymc3.find_MAP()` estimates the model paramters with the [maximum a posteriori (MAP) method](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation).\n",
    "\n",
    "- `pm.NUTS()` uses the [No-U-Turn Sampler (NUTS)](https://arxiv.org/abs/1111.4246) to generate posterior samples.\n",
    "- Note that for reproducibility we use the `random_seed` parameter in `pymc3.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2ed63b5a916113126794244873d83a86",
     "grade": false,
     "grade_id": "get_trace_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_trace(X, y, n_samples=1000, random_seed=0):\n",
    "    \"\"\"\n",
    "    A simple Bayesian linear regression model with normal priors.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    X: A numpy array\n",
    "    y: A numpy array\n",
    "    n_samples: The number of samples to draw in pymc3.sample().\n",
    "               Defaults to 1000.\n",
    "    random_seed: An int. Used in pymc3.sample().\n",
    "                 Defaults to 0.\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    A pymc3.MultiTrace object with access to sampling values.\n",
    "    \"\"\"\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        y = pm.Normal('y', mu=y_exp, sd=sigma, observed=y)\n",
    "        \n",
    "        start = pm.find_MAP()\n",
    "        step = pm.NUTS(scaling=start)\n",
    "        trace = pm.sample(n_samples, step=step, start=start, random_seed=random_seed)\n",
    "        \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the sampler has been created, we can use it to create a chain of sampled parameter values, which are known as _traces_. After a (large) number of samples have been generated, these traces will provide posterior distributions for the model parameters. Thus, we can use the traces to not only obtain the model parameter values, but a statistical characterization for these values.\n",
    "\n",
    "The following code cell may take a while to complete. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "214f865547c20ca4085d9f5804595dd4",
     "grade": false,
     "grade_id": "get_trace_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trace = get_trace(data.Distance.values, data.AirTime.values, n_samples=1000, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a99d0cb4ebe98444bbe193c4418a29bd",
     "grade": true,
     "grade_id": "test_1",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(trace, pm.backends.base.MultiTrace)\n",
    "\n",
    "assert_true('alpha' in trace.varnames)\n",
    "assert_true('beta' in trace.varnames)\n",
    "assert_true('sigma' in trace.varnames)\n",
    "\n",
    "for v in trace.varnames:\n",
    "    assert_equal(len(trace[v]), 1000)\n",
    "\n",
    "assert_almost_equal(trace['alpha'][0], 0.40060267400537569)\n",
    "assert_almost_equal(trace['beta'][0], 0.13549270335335292)\n",
    "assert_almost_equal(trace['sigma'][0], 11.635038372477414)\n",
    "\n",
    "assert_array_almost_equal(\n",
    "    trace['alpha'][-5:],\n",
    "    [ 1.552465,  1.573076,  1.571528,  1.571528,  1.374191]\n",
    "    )\n",
    "assert_array_almost_equal(\n",
    "    trace['beta'][-5:],\n",
    "    [ 0.127634,  0.129961,  0.135609,  0.135609,  0.130797]\n",
    "    )\n",
    "assert_array_almost_equal(\n",
    "    trace['sigma'][-5:],\n",
    "    [ 16.317306,  16.641373,  16.73387 ,  16.73387 ,  16.804086]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7a5330466f09b0a5388451b2bfc37511",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's check our model by inspecting the sampling output. A simple posterior plot can be created using `traceplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7aec890312ed2217c09c82a4fcea6256",
     "grade": false,
     "grade_id": "traceplot",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot traces\n",
    "sns.set_style('darkgrid')\n",
    "pm.traceplot(trace[-1000:], ['alpha', 'beta', 'sigma'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visually inspect the fit of our model by displaying the data points and the best fit regression line (along with error estimation), all in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "424e21294eaca6990fb9dba0df033a9c",
     "grade": false,
     "grade_id": "plot",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "x = data.Distance.values\n",
    "y = data.AirTime.values\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x, y, c=sns.xkcd_rgb['denim blue'], label = 'Sample Data')\n",
    "\n",
    "xl = x.min()\n",
    "xh = x.max()\n",
    "\n",
    "intercepts = trace['alpha'][-n_samples:]\n",
    "slopes = trace['beta'][-n_samples:]\n",
    "\n",
    "for m, b in zip(slopes, intercepts):\n",
    "    yl = m * xl + b\n",
    "    yh = m * xh + b\n",
    "    ax.plot((xl, xh), (yl, yh), color=sns.xkcd_rgb['medium green'], lw=0.1, alpha = 0.1)\n",
    "\n",
    "# Replot last one to get legend label\n",
    "ax.plot((xl, xh), (yl, yh), color=sns.xkcd_rgb['medium green'], lw=0.1, label = 'Posterior Prediction')\n",
    "\n",
    "m_fit = slopes.mean()\n",
    "b_fit = intercepts.mean()\n",
    "\n",
    "yfl = b_fit + m_fit * xl\n",
    "yfh = b_fit + m_fit * xh\n",
    "ax.plot((xl, xh), (yfl, yfh), color=sns.xkcd_rgb['pale red'], lw=3, label='Model Regression')\n",
    "\n",
    "ax.set_xlim(0, 2000)\n",
    "ax.set_ylim(0, 300)\n",
    "\n",
    "ax.legend(loc='upper left', frameon=True)\n",
    "\n",
    "ax.set_xlabel('Distance (miles)')\n",
    "ax.set_ylabel('Air time (min)')\n",
    "\n",
    "sns.despine(offset=10, trim=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
